{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "import keras\n",
    "import numpy as np\n",
    "import numba as nb\n",
    "from utils import *\n",
    "from tqdm import *\n",
    "from evaluate import evaluate\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "from keras.layers import *\n",
    "from layer import NR_GraphAttention\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"]=\"2\"\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True  \n",
    "sess = tf.Session(config=config)  \n",
    "\n",
    "seed = 12306\n",
    "np.random.seed(seed)\n",
    "tf.compat.v1.set_random_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39594 2453\n"
     ]
    }
   ],
   "source": [
    "train_pair,dev_pair,adj_matrix,r_index,r_val,adj_features,rel_features = load_data(\"data/ja_en/\",train_ratio=0.30)\n",
    "adj_matrix = np.stack(adj_matrix.nonzero(),axis = 1)\n",
    "rel_matrix,rel_val = np.stack(rel_features.nonzero(),axis = 1),rel_features.data\n",
    "ent_matrix,ent_val = np.stack(adj_features.nonzero(),axis = 1),adj_features.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_size = adj_features.shape[0]\n",
    "rel_size = rel_features.shape[1]\n",
    "triple_size = len(adj_matrix)\n",
    "node_hidden = 128\n",
    "rel_hidden = 128\n",
    "batch_size = 1024\n",
    "dropout_rate = 0.3\n",
    "lr = 0.005\n",
    "gamma = 1\n",
    "depth = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(index_a,index_b,vec = None):\n",
    "    if vec is None:\n",
    "        inputs = [adj_matrix,r_index,r_val,rel_matrix,ent_matrix]\n",
    "        inputs = [np.expand_dims(item,axis=0) for item in inputs]\n",
    "        vec = get_emb.predict_on_batch(inputs)\n",
    "    Lvec = np.array([vec[e] for e in index_a])\n",
    "    Rvec = np.array([vec[e] for e in index_b])\n",
    "    Lvec = Lvec / (np.linalg.norm(Lvec,axis=-1,keepdims=True)+1e-5)\n",
    "    Rvec = Rvec / (np.linalg.norm(Rvec,axis=-1,keepdims=True)+1e-5)\n",
    "    return Lvec,Rvec\n",
    "\n",
    "class TokenEmbedding(keras.layers.Embedding):\n",
    "    \"\"\"Embedding layer with weights returned.\"\"\"\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return self.input_dim, self.output_dim\n",
    "\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        return None\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self.embeddings\n",
    "    \n",
    "def get_trgat(node_hidden,rel_hidden,triple_size=triple_size,node_size=node_size,rel_size=rel_size,dropout_rate = 0,gamma = 3,lr = 0.005,depth = 2):\n",
    "    adj_input = Input(shape=(None,2))\n",
    "    index_input = Input(shape=(None,2),dtype='int64')\n",
    "    val_input = Input(shape = (None,))\n",
    "    rel_adj = Input(shape=(None,2))\n",
    "    ent_adj = Input(shape=(None,2))\n",
    "    \n",
    "    ent_emb = TokenEmbedding(node_size,node_hidden,trainable = True)(val_input) \n",
    "    rel_emb = TokenEmbedding(rel_size,node_hidden,trainable = True)(val_input)\n",
    "    \n",
    "    def avg(tensor,size):\n",
    "        adj = K.cast(K.squeeze(tensor[0],axis = 0),dtype = \"int64\")   \n",
    "        adj = tf.SparseTensor(indices=adj, values=tf.ones_like(adj[:,0],dtype = 'float32'), dense_shape=(node_size,size)) \n",
    "        adj = tf.sparse_softmax(adj) \n",
    "        return tf.sparse_tensor_dense_matmul(adj,tensor[1])\n",
    "    \n",
    "    opt = [rel_emb,adj_input,index_input,val_input]\n",
    "    ent_feature = Lambda(avg,arguments={'size':node_size})([ent_adj,ent_emb])\n",
    "    rel_feature = Lambda(avg,arguments={'size':rel_size})([rel_adj,rel_emb])\n",
    "    \n",
    "    e_encoder = NR_GraphAttention(node_size,activation=\"tanh\",\n",
    "                                       rel_size = rel_size,\n",
    "                                       use_bias = True,\n",
    "                                       depth = depth,\n",
    "                                       triple_size = triple_size)\n",
    "    \n",
    "    r_encoder = NR_GraphAttention(node_size,activation=\"tanh\",\n",
    "                                       rel_size = rel_size,\n",
    "                                       use_bias = True,\n",
    "                                       depth = depth,\n",
    "                                       triple_size = triple_size)\n",
    "    \n",
    "    out_feature = Concatenate(-1)([e_encoder([ent_feature]+opt),r_encoder([rel_feature]+opt)])\n",
    "    out_feature = Dropout(dropout_rate)(out_feature)\n",
    "    \n",
    "    alignment_input = Input(shape=(None,2))\n",
    "    \n",
    "    def align_loss(tensor): \n",
    "        \n",
    "        def squared_dist(x):\n",
    "            A,B = x\n",
    "            row_norms_A = tf.reduce_sum(tf.square(A), axis=1)\n",
    "            row_norms_A = tf.reshape(row_norms_A, [-1, 1])  # Column vector.\n",
    "            row_norms_B = tf.reduce_sum(tf.square(B), axis=1)\n",
    "            row_norms_B = tf.reshape(row_norms_B, [1, -1])  # Row vector.\n",
    "            return row_norms_A + row_norms_B - 2 * tf.matmul(A, B,transpose_b=True) \n",
    "        \n",
    "        emb = tensor[1]\n",
    "        l,r = K.cast(tensor[0][0,:,0],'int32'),K.cast(tensor[0][0,:,1],'int32')\n",
    "        l_emb,r_emb = K.gather(reference=emb,indices=l),K.gather(reference=emb,indices=r)\n",
    "        \n",
    "        pos_dis = K.sum(K.square(l_emb-r_emb),axis=-1,keepdims=True)\n",
    "        r_neg_dis = squared_dist([r_emb,emb])\n",
    "        l_neg_dis = squared_dist([l_emb,emb])\n",
    "        \n",
    "        l_loss = pos_dis - l_neg_dis + gamma\n",
    "        l_loss = l_loss *(1 - K.one_hot(indices=l,num_classes=node_size) - K.one_hot(indices=r,num_classes=node_size))\n",
    "        \n",
    "        r_loss = pos_dis - r_neg_dis + gamma\n",
    "        r_loss = r_loss *(1 - K.one_hot(indices=l,num_classes=node_size) - K.one_hot(indices=r,num_classes=node_size))\n",
    "        \n",
    "        r_loss = (r_loss - K.stop_gradient(K.mean(r_loss,axis=-1,keepdims=True))) / K.stop_gradient(K.std(r_loss,axis=-1,keepdims=True))\n",
    "        l_loss = (l_loss - K.stop_gradient(K.mean(l_loss,axis=-1,keepdims=True))) / K.stop_gradient(K.std(l_loss,axis=-1,keepdims=True))\n",
    "        \n",
    "        lamb,tau = 30, 10\n",
    "        l_loss = K.logsumexp(lamb*l_loss+tau,axis=-1)\n",
    "        r_loss = K.logsumexp(lamb*r_loss+tau,axis=-1)\n",
    "        return K.mean(l_loss + r_loss)\n",
    "\n",
    "    loss = Lambda(align_loss)([alignment_input,out_feature])\n",
    "\n",
    "    inputs = [adj_input,index_input,val_input,rel_adj,ent_adj]\n",
    "    train_model = keras.Model(inputs = inputs + [alignment_input],outputs = loss)\n",
    "    train_model.compile(loss=lambda y_true,y_pred: y_pred,optimizer=keras.optimizers.rmsprop(lr))\n",
    "    \n",
    "    feature_model = keras.Model(inputs = inputs,outputs = out_feature)\n",
    "    \n",
    "    return train_model,feature_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            (None, None, 2)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "token_embedding_1 (TokenEmbeddi (39594, 128)         5068032     input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "token_embedding_2 (TokenEmbeddi (4906, 128)          627968      input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, None, 2)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (39594, 128)         0           input_5[0][0]                    \n",
      "                                                                 token_embedding_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            (None, None, 2)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, None, 2)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (39594, 128)         0           input_4[0][0]                    \n",
      "                                                                 token_embedding_2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "nr__graph_attention_1 (NR_Graph (39594, 384)         172672      lambda_1[0][0]                   \n",
      "                                                                 token_embedding_2[0][0]          \n",
      "                                                                 input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "nr__graph_attention_2 (NR_Graph (39594, 384)         172672      lambda_2[0][0]                   \n",
      "                                                                 token_embedding_2[0][0]          \n",
      "                                                                 input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (39594, 768)         0           nr__graph_attention_1[0][0]      \n",
      "                                                                 nr__graph_attention_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            (None, None, 2)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (39594, 768)         0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               ()                   0           input_6[0][0]                    \n",
      "                                                                 dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 6,041,344\n",
      "Trainable params: 6,041,344\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model,get_emb = get_trgat(dropout_rate=dropout_rate,\n",
    "                          node_size=node_size,\n",
    "                          rel_size=rel_size,\n",
    "                          depth=depth,\n",
    "                          gamma =gamma,\n",
    "                          node_hidden=node_hidden,\n",
    "                          rel_hidden=rel_hidden,\n",
    "                          lr=lr)\n",
    "\n",
    "evaluater = evaluate(dev_pair)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:27<00:00,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hits@1:  0.7281904761904762   Hits@5:  0.8917142857142857   Hits@10:  0.9283809523809524   MRR:  0.8009654727674898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hits@1:  0.768095238095238   Hits@5:  0.9108571428571428   Hits@10:  0.9416190476190476   MRR:  0.83114820179549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 5/5 [00:17<00:00,  3.47s/it]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hits@1:  0.7983809523809524   Hits@5:  0.918   Hits@10:  0.9453333333333334   MRR:  0.8515206988308791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:18<00:00,  3.60s/it]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hits@1:  0.807047619047619   Hits@5:  0.9200952380952381   Hits@10:  0.9447619047619048   MRR:  0.8576288977211289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:19<00:00,  3.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hits@1:  0.8064761904761905   Hits@5:  0.92   Hits@10:  0.9437142857142857   MRR:  0.857417648499695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "rest_set_1 = [e1 for e1, e2 in dev_pair]\n",
    "rest_set_2 = [e2 for e1, e2 in dev_pair]\n",
    "np.random.shuffle(rest_set_1)\n",
    "np.random.shuffle(rest_set_2)\n",
    "\n",
    "epoch = 20\n",
    "for turn in range(5):\n",
    "    for i in trange(epoch):\n",
    "        np.random.shuffle(train_pair)\n",
    "        for pairs in [train_pair[i*batch_size:(i+1)*batch_size] for i in range(len(train_pair)//batch_size + 1)]:\n",
    "            if len(pairs) == 0:\n",
    "                continue\n",
    "            inputs = [adj_matrix,r_index,r_val,rel_matrix,ent_matrix,pairs]\n",
    "            inputs = [np.expand_dims(item,axis=0) for item in inputs]\n",
    "            model.train_on_batch(inputs,np.zeros((1,1)))\n",
    "        if i==epoch-1:\n",
    "            Lvec,Rvec = get_embedding(dev_pair[:,0],dev_pair[:,1])\n",
    "            evaluater.test(Lvec,Rvec)\n",
    "        new_pair = []   \n",
    "    Lvec,Rvec = get_embedding(rest_set_1,rest_set_2)\n",
    "    A,B = evaluater.CSLS_cal(Lvec,Rvec,False)\n",
    "    for i,j in enumerate(A):\n",
    "        if  B[j] == i:\n",
    "            new_pair.append([rest_set_1[j],rest_set_2[i]])\n",
    "    \n",
    "    train_pair = np.concatenate([train_pair,np.array(new_pair)],axis = 0)\n",
    "    for e1,e2 in new_pair:\n",
    "        if e1 in rest_set_1:\n",
    "            rest_set_1.remove(e1) \n",
    "        \n",
    "    for e1,e2 in new_pair:\n",
    "        if e2 in rest_set_2:\n",
    "            rest_set_2.remove(e2)\n",
    "    epoch = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
